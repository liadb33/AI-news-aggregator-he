{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPiAGdp3YU5ZSZBW5WMRK6n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hrnrxb/AI-News-Aggregator-Bot/blob/main/Telegram_AI_News_Aggregator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOaAklxTgS_y",
        "outputId": "4b8cd529-41a9-43c5-eaf6-08ca43a53663"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-telegram-bot in /usr/local/lib/python3.11/dist-packages (22.2)\n",
            "Requirement already satisfied: feedparser in /usr/local/lib/python3.11/dist-packages (6.0.11)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: httpx<0.29,>=0.27 in /usr/local/lib/python3.11/dist-packages (from python-telegram-bot) (0.28.1)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.11/dist-packages (from feedparser) (1.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.7.9)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->python-telegram-bot) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->python-telegram-bot) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29,>=0.27->python-telegram-bot) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29,>=0.27->python-telegram-bot) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install python-telegram-bot feedparser beautifulsoup4 requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from telegram import Bot\n",
        "import os\n",
        "\n",
        "# Your Telegram bot token.\n",
        "# For local testing, you can place it directly here.\n",
        "# For production (GitHub Actions), use GitHub Secrets for security.\n",
        "TELEGRAM_BOT_TOKEN = \"\"\n",
        "\n",
        "# Your Telegram channel ID where the bot will send messages.\n",
        "# This can be the channel's username (e.g., \"@YourChannelName\")\n",
        "# or the numeric ID for private channels (e.g., -100123456789).\n",
        "TELEGRAM_CHANNEL_ID = \"\"\n",
        "\n",
        "# Initialize the Telegram Bot object with your token.\n",
        "bot = Bot(token=TELEGRAM_BOT_TOKEN)\n",
        "\n",
        "print(\"Initial Telegram bot setup complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVDsefJ_g9t0",
        "outputId": "0004fd79-6729-43e1-823a-6cf3c04eecbf"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Telegram bot setup complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "\n",
        "async def test_telegram_message():\n",
        "    \"\"\"\n",
        "    Sends a test message to the configured Telegram channel.\n",
        "    Verifies if the bot can successfully send messages.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        await bot.send_message(chat_id=TELEGRAM_CHANNEL_ID, text=\"HelloWWWW! This is a test message from  news bot.\")\n",
        "        print(\"Test message successfully sent to Telegram.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error sending test message: {e}\")\n",
        "        print(\"Please ensure your bot token and channel ID are correct, and the bot is an admin in the channel.\")\n",
        "\n",
        "# Execute the asynchronous test function.\n",
        "await test_telegram_message()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDPYxG24iDK0",
        "outputId": "aa64d008-a91d-4eea-e949-65246a7513cf"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test message successfully sent to Telegram.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# File to store previously sent links.\n",
        "# This will be replaced by a more persistent storage (like SQLite) for GitHub Actions.\n",
        "SENT_LINKS_FILE = \"sent_links.txt\"\n",
        "\n",
        "def load_sent_links():\n",
        "    \"\"\"Loads previously sent links from the file.\"\"\"\n",
        "    if not os.path.exists(SENT_LINKS_FILE):\n",
        "        return set()\n",
        "    with open(SENT_LINKS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "        return set(f.read().splitlines())\n",
        "\n",
        "def save_sent_link(link):\n",
        "    \"\"\"Appends a new link to the file of sent links.\"\"\"\n",
        "    with open(SENT_LINKS_FILE, \"a\", encoding=\"utf-8\") as f:\n",
        "        f.write(link + \"\\n\")\n",
        "\n",
        "# Load existing sent links when the script starts.\n",
        "sent_links = load_sent_links()\n",
        "\n",
        "print(f\"Number of previously sent links loaded: {len(sent_links)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB_YDqj0iUxa",
        "outputId": "cb2aa662-0d21-4d2f-fb09-f97b1aa1b510"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of previously sent links loaded: 70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import feedparser\n",
        "from bs4 import BeautifulSoup # Make sure BeautifulSoup is imported at the top of your script\n",
        "\n",
        "def get_rss_feed_items(feed_url, source_name, limit=10):\n",
        "    \"\"\"\n",
        "    Retrieves new news items from an RSS feed, including title, link, and summary.\n",
        "    No emoji prefix is added here, as it's handled by format_telegram_post.\n",
        "\n",
        "    Args:\n",
        "        feed_url (str): The URL of the RSS feed.\n",
        "        source_name (str): The name of the source (e.g., \"Hugging Face Blog\").\n",
        "        limit (int): Maximum number of items to return.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of tuples (title, link, summary, source_name_for_emoji_lookup).\n",
        "    \"\"\"\n",
        "    print(f\"Retrieving news from RSS: {source_name} ({feed_url})\")\n",
        "    items = []\n",
        "    try:\n",
        "        feed = feedparser.parse(feed_url)\n",
        "        for entry in feed.entries[:limit]:\n",
        "            title = getattr(entry, 'title', \"No Title\")\n",
        "            link = getattr(entry, 'link', None)\n",
        "            # Try to get summary or description, otherwise use title as a fallback\n",
        "            summary = getattr(entry, 'summary', getattr(entry, 'description', title))\n",
        "\n",
        "            # Clean up HTML tags from summary if any\n",
        "            summary = BeautifulSoup(summary, \"html.parser\").get_text(separator=' ', strip=True)\n",
        "            summary = (summary[:200] + '...') if len(summary) > 200 else summary # Truncate summary\n",
        "\n",
        "            if link and link not in sent_links:\n",
        "                # Format title: \"Source Name: Actual Title\"\n",
        "                # Pass source_name again as the fourth item for emoji lookup in format_telegram_post\n",
        "                items.append((f\"{source_name}: {title}\", link, summary, source_name))\n",
        "            else:\n",
        "                if link:\n",
        "                    print(f\"Duplicate link from {source_name} ignored: {link}\")\n",
        "        return items\n",
        "    except Exception as e:\n",
        "        print(f\"Error retrieving RSS from {source_name}: {e}\")\n",
        "        return []\n",
        "\n",
        "# Example usage (you can test this in a separate cell if needed)\n",
        "# hf_blog_news = get_rss_feed_items(\"https://huggingface.co/blog/rss.xml\", \"Hugging Face Blog\")\n",
        "# print(f\"Hugging Face Blog News (with summary): {hf_blog_news}\")\n",
        "\n",
        "# arxiv_nlp_news = get_rss_feed_items(\"http://export.arxiv.org/rss/cs.CL\", \"arXiv NLP\")\n",
        "# print(f\"arXiv NLP News (with summary): {arxiv_nlp_news}\")\n",
        "\n",
        "# openai_blog_news = get_rss_feed_items(\"https://openai.com/blog/rss.xml\", \"OpenAI Blog\")\n",
        "# print(f\"OpenAI Blog News (with summary): {openai_blog_news}\")\n",
        "\n",
        "# google_ai_blog_news = get_rss_feed_items(\"https://ai.googleblog.com/feeds/posts/default\", \"Google AI Blog\")\n",
        "# print(f\"Google AI Blog News (with summary): {google_ai_blog_news}\")\n",
        "\n",
        "# papers_with_code_blog_news = get_rss_feed_items(\"https://paperswithcode.com/rss\", \"Papers With Code\")\n",
        "# print(f\"Papers With Code Blog News (with summary): {papers_with_code_blog_news}\")\n",
        "\n",
        "# deepmind_blog_news = get_rss_feed_items(\"https://deepmind.com/blog/feed/basic/\", \"DeepMind Blog\")\n",
        "# print(f\"DeepMind Blog News (with summary): {deepmind_blog_news}\")\n",
        "\n",
        "# kaggle_blog_news = get_rss_feed_items(\"https://www.kaggle.com/blog/rss/\", \"Kaggle Blog\")\n",
        "# print(f\"Kaggle Blog News (with summary): {kaggle_blog_news}\")"
      ],
      "metadata": {
        "id": "4xSSFPEhimsC"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup # Make sure BeautifulSoup is imported at the top of your script\n",
        "\n",
        "def get_hacker_news_items(limit=10):\n",
        "    \"\"\"\n",
        "    Retrieves top news items from Hacker News API, including title, link, and a short summary.\n",
        "    No emoji prefix is added here, as it's handled by format_telegram_post.\n",
        "\n",
        "    Args:\n",
        "        limit (int): Maximum number of items to return.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of tuples (title, link, summary, source_name_for_emoji_lookup).\n",
        "    \"\"\"\n",
        "    source_name = \"Hacker News\" # Explicitly define source name for emoji lookup\n",
        "    print(f\"Retrieving news from Hacker News\")\n",
        "    items = []\n",
        "    try:\n",
        "        # Get IDs of top stories\n",
        "        top_stories_url = \"https://hacker-news.firebaseio.com/v0/topstories.json\"\n",
        "        top_story_ids = requests.get(top_stories_url).json()\n",
        "\n",
        "        # Fetch details for each story ID\n",
        "        for story_id in top_story_ids[:limit]:\n",
        "            item_url = f\"https://hacker-news.firebaseio.com/v0/item/{story_id}.json\"\n",
        "            story_data = requests.get(item_url).json()\n",
        "\n",
        "            title = story_data.get('title', \"No Title\")\n",
        "            # If 'url' is not available, use the Hacker News discussion page link\n",
        "            link = story_data.get('url', f\"https://news.ycombinator.com/item?id={story_id}\")\n",
        "\n",
        "            # Hacker News API often lacks a direct summary; use 'text' or a default message\n",
        "            summary = story_data.get('text', \"Click to read more or join the discussion.\")\n",
        "            # Clean up HTML tags from summary and truncate it\n",
        "            summary = BeautifulSoup(summary, \"html.parser\").get_text(separator=' ', strip=True)\n",
        "            summary = (summary[:200] + '...') if len(summary) > 200 else summary\n",
        "\n",
        "            if title and link and link not in sent_links:\n",
        "                # Format title: \"Source Name: Actual Title\"\n",
        "                # Pass source_name again as the fourth item for emoji lookup in format_telegram_post\n",
        "                items.append((f\"{source_name}: {title}\", link, summary, source_name))\n",
        "            else:\n",
        "                if link:\n",
        "                    print(f\"Duplicate link from Hacker News ignored: {link}\")\n",
        "        return items\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error retrieving Hacker News: {e}\")\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"General error in Hacker News: {e}\")\n",
        "        return []\n",
        "\n",
        "# Example usage (you can test this in a separate cell if needed)\n",
        "# hn_news = get_hacker_news_items(limit=5)\n",
        "# print(f\"Hacker News News (with summary): {hn_news}\")"
      ],
      "metadata": {
        "id": "N4BCkCS2qrn7"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def get_github_trending_repos(language=\"python\", limit=10):\n",
        "    \"\"\"\n",
        "    Scrapes trending GitHub repositories, including title, link, and description.\n",
        "    No emoji prefix is added here, as it's handled by format_telegram_post.\n",
        "\n",
        "    Args:\n",
        "        language (str): The programming language to search for (e.g., \"python\").\n",
        "        limit (int): Maximum number of repositories to return.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of tuples (title, link, summary, source_name_for_emoji_lookup).\n",
        "    \"\"\"\n",
        "    source_name = f\"GitHub Trending ({language})\" # Explicitly define source name for emoji lookup\n",
        "    url = f\"https://github.com/trending/{language}\"\n",
        "    print(f\"Retrieving news from GitHub Trending: {language} ({url})\")\n",
        "    items = []\n",
        "    try:\n",
        "        res = requests.get(url)\n",
        "        res.raise_for_status()\n",
        "        soup = BeautifulSoup(res.text, \"html.parser\")\n",
        "\n",
        "        # Selector for trending repositories. Adapt if GitHub UI changes.\n",
        "        for article_tag in soup.select(\"article.Box-row\")[:limit]:\n",
        "            title_tag = article_tag.select_one(\"h2 a\")\n",
        "            description_tag = article_tag.select_one(\"p.col-9\") # Selector for description\n",
        "\n",
        "            repo_name = title_tag.text.strip().replace(\"\\n\", \"\").replace(\" \", \"\") if title_tag else \"No Repository Name\"\n",
        "            link = \"https://github.com\" + title_tag[\"href\"] if title_tag and \"href\" in title_tag.attrs else None\n",
        "            summary = description_tag.text.strip() if description_tag else \"No description available.\"\n",
        "            summary = (summary[:200] + '...') if len(summary) > 200 else summary # Truncate summary\n",
        "\n",
        "            if link and link not in sent_links:\n",
        "                # Format title: \"Source Name: Actual Title\"\n",
        "                # Pass source_name again as the fourth item for emoji lookup in format_telegram_post\n",
        "                items.append((f\"{source_name}: {repo_name}\", link, summary, source_name))\n",
        "            else:\n",
        "                if link:\n",
        "                    print(f\"Duplicate link from GitHub Trending ignored: {link}\")\n",
        "        return items\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error retrieving GitHub Trending: {e}\")\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"General error in GitHub Trending: {e}\")\n",
        "        return []\n",
        "\n",
        "# Example usage (you can test this in a separate cell if needed)\n",
        "# github_news = get_github_trending_repos(language=\"python\")\n",
        "# print(f\"GitHub Trending News (with description): {github_news}\")"
      ],
      "metadata": {
        "id": "mBXWZ29-jJa5"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_source_emoji(source_name):\n",
        "    \"\"\"\n",
        "    Returns an appropriate emoji based on the news source's name.\n",
        "\n",
        "    Args:\n",
        "        source_name (str): The clean name of the news source (e.g., \"Hugging Face Blog\").\n",
        "\n",
        "    Returns:\n",
        "        str: An emoji string.\n",
        "    \"\"\"\n",
        "    emoji_map = {\n",
        "        # RSS Feeds\n",
        "        \"Hugging Face Blog\": \"ü§ó\",  # Blog posts from Hugging Face\n",
        "        \"Hugging Face Paper\": \"üìù\", # Papers/research related to Hugging Face from JamesG's blog\n",
        "        \"ML Reddit\": \"ü§ñ\",          # Machine Learning discussions from Reddit\n",
        "        \"OpenAI Blog\": \"‚ú®\",        # OpenAI's latest breakthroughs\n",
        "        \"The Gradient\": \"üìú\",       # In-depth articles and essays on AI\n",
        "        \"Jay Alammar\": \"üí°\",        # Visual explanations and deep dives\n",
        "        \"DeepMind Blog\": \"üî¨\",       # Scientific research from DeepMind\n",
        "        \"AI From MIT News\": \"üéì\",   # AI news directly from MIT\n",
        "        \"General News From MIT News\": \"üèõÔ∏è\", # Broader tech/science from MIT\n",
        "        \"Microsoft AI Blog\": \"üíª\",  # Microsoft's AI advancements\n",
        "        \"machinelearningmastery Blog\": \"üë®‚Äçüè´\", # Practical ML tutorials\n",
        "        \"Nvidia AI Blog\": \"üöÄ\",     # NVIDIA's AI hardware & software news\n",
        "        \"Towards Data Science\": \"üìä\",# Data Science articles and tutorials\n",
        "        \"Hacker News\": \"HN\",        # No emoji, just \"HN\" prefix for classic feel\n",
        "\n",
        "        # GitHub Trending (using specific language/topic emojis where applicable)\n",
        "        \"GitHub Trending (python)\": \"üêç\",\n",
        "        \"GitHub Trending (jupyter-notebook)\": \"üìì\",\n",
        "        \"GitHub Trending (google colab)\": \"‚òÅÔ∏è\", # Google Colab specific\n",
        "        \"GitHub Trending (Artificial Intelligence)\": \"üß†\",\n",
        "        \"GitHub Trending (AI)\": \"üß†\",\n",
        "        \"GitHub Trending (machine-learning)\": \"üìà\",\n",
        "        \"GitHub Trending (deep-learning)\": \"üåå\", # Deep learning, cosmic feel\n",
        "        \"GitHub Trending (nlp)\": \"üó£Ô∏è\", # Natural Language Processing, talking\n",
        "        \"GitHub Trending (Natural Language Processing)\": \"üó£Ô∏è\",\n",
        "        \"GitHub Trending (CV)\": \"üëÅÔ∏è\", # Computer Vision, eye\n",
        "        \"GitHub Trending (Computer Vision)\": \"üëÅÔ∏è\",\n",
        "        \"GitHub Trending (Data Science)\": \"üß™\", # Data Science, lab/experiment\n",
        "        \"GitHub Trending (Awesome Lists)\": \"‚≠ê\", # Curated lists\n",
        "    }\n",
        "    # Return the specific emoji for the source, or a default sparkle emoji if not found.\n",
        "    return emoji_map.get(source_name, \"‚ú®\")\n",
        "\n",
        "print(\"Source emoji mapping defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8vums2T0VBx",
        "outputId": "ffd74cb4-d59d-40c9-e283-11070b601235"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source emoji mapping defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collect_all_news():\n",
        "    \"\"\"\n",
        "    Collects and aggregates news items from various sources (RSS, GitHub Trending, Hacker News).\n",
        "    Ensures uniqueness of news items based on their links.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of tuples, each containing (title, link, summary, source_name_for_emoji_lookup).\n",
        "    \"\"\"\n",
        "    all_news_items = []\n",
        "\n",
        "    print(\"\\n--- Starting News Collection ---\")\n",
        "\n",
        "    # 1. Collect from RSS Feeds\n",
        "\n",
        "    all_news_items.extend(get_rss_feed_items(\"https://hf.co/blog/feed.xml\", \"Hugging Face Blog\", limit=10))\n",
        "    all_news_items.extend(get_rss_feed_items(\"https://jamesg.blog/hf-papers.xml\", \"Hugging Face Paper\", limit=10))\n",
        "    all_news_items.extend(get_rss_feed_items(\"https://www.reddit.com/r/MachineLearning/.rss\", \"ML Reddit\", limit=10))\n",
        "    all_news_items.extend(get_rss_feed_items(\"https://openai.com/blog/rss.xml\", \"OpenAI Blog\", limit=10))\n",
        "    all_news_items.extend(get_rss_feed_items(\"https://thegradient.pub/rss/\", \"The Gradient\", limit=10))\n",
        "    all_news_items.extend(get_rss_feed_items(\"https://jalammar.github.io/feed.xml\", \"Jay Alammar\", limit=10))\n",
        "    all_news_items.extend(get_rss_feed_items(\"https://deepmind.google/blog/rss.xml\", \"DeepMind Blog\", limit=10))\n",
        "    all_news_items.extend(get_rss_feed_items(\"https://news.mit.edu/rss/topic/artificial-intelligence2\", \"AI From MIT News\", limit=10))\n",
        "    all_news_items.extend(get_rss_feed_items(\"https://www.technologyreview.com/feed/\", \"General News From MIT News\", limit=10))\n",
        "    all_news_items.extend(get_rss_feed_items(\"https://blogs.microsoft.com/ai/feed/\", \"Microsoft AI Blog\", limit=10))\n",
        "    all_news_items.extend(get_rss_feed_items(\"https://machinelearningmastery.com/blog/feed/\", \"machinelearningmastery Blog\", limit=10))\n",
        "    all_news_items.extend(get_rss_feed_items(\"https://blogs.nvidia.com/blog/category/ai/feed/\", \"Nvidia AI Blog\", limit=10))\n",
        "    all_news_items.extend(get_rss_feed_items(\"https://towardsdatascience.com/feed/\", \"Towards Data Science\", limit=10))\n",
        "\n",
        "    # 2. Collect from GitHub Trending\n",
        "\n",
        "    all_news_items.extend(get_github_trending_repos(language=\"python\", limit=10))\n",
        "    all_news_items.extend(get_github_trending_repos(language=\"jupyter-notebook\", limit=10))\n",
        "    all_news_items.extend(get_github_trending_repos(language=\"google colab\", limit=10))\n",
        "    all_news_items.extend(get_github_trending_repos(language=\"Artificial Intelligence\", limit=10))\n",
        "    all_news_items.extend(get_github_trending_repos(language=\"AI\", limit=10))\n",
        "    all_news_items.extend(get_github_trending_repos(language=\"machine-learning\", limit=10))\n",
        "    all_news_items.extend(get_github_trending_repos(language=\"deep-learning\", limit=10))\n",
        "    all_news_items.extend(get_github_trending_repos(language=\"nlp\", limit=10))\n",
        "    all_news_items.extend(get_github_trending_repos(language=\"Natural Language Processing\", limit=10))\n",
        "    all_news_items.extend(get_github_trending_repos(language=\"CV\", limit=10))\n",
        "    all_news_items.extend(get_github_trending_repos(language=\"Computer Vision\", limit=10))\n",
        "    all_news_items.extend(get_github_trending_repos(language=\"Data Science\", limit=10))\n",
        "    all_news_items.extend(get_github_trending_repos(language=\"Awesome Lists\", limit=10))\n",
        "\n",
        "\n",
        "    # 3. Collect from Hacker News API\n",
        "    all_news_items.extend(get_hacker_news_items(limit=10))\n",
        "\n",
        "    # Remove duplicates. Using a dictionary preserves insertion order (Python 3.7+)\n",
        "    # and ensures uniqueness based on the link.\n",
        "    unique_news_items = {}\n",
        "    # Unpack all 4 values from the tuple, as get_ functions now return 4 items.\n",
        "    for title, link, summary, source_name_for_emoji_lookup in all_news_items:\n",
        "        unique_news_items[link] = (title, link, summary, source_name_for_emoji_lookup)\n",
        "\n",
        "    final_news_list = list(unique_news_items.values())\n",
        "\n",
        "    print(f\"Total unique new items collected: {len(final_news_list)}\")\n",
        "    print(\"--- News Collection Finished ---\")\n",
        "\n",
        "    # You can add sorting logic here if you want to sort items by date, etc.\n",
        "    return final_news_list\n",
        "\n",
        "# Example usage (you can run this in a separate cell for testing):\n",
        "# fetched_news = collect_all_news()\n",
        "# print(\"\\nNew items ready for dispatch:\")\n",
        "# for title, link, summary, source_name_for_emoji_lookup in fetched_news:\n",
        "#     print(f\"- {source_name_for_emoji_lookup}: {title}\\n  Summary: {summary}\\n  Link: {link}\\n\")"
      ],
      "metadata": {
        "id": "vwXp5UzQlY1i"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from telegram.constants import ParseMode\n",
        "\n",
        "# Define the channel ID for the footer.\n",
        "# This global variable should be defined once at the top of your script (e.g., in Cell 2).\n",
        "TELEGRAM_CHANNEL_ID_FOR_FOOTER = \"\"\n",
        "\n",
        "def format_telegram_post(title, link, summary, source_name_for_emoji_lookup):\n",
        "    \"\"\"\n",
        "    Formats the news item into an HTML string suitable for Telegram.\n",
        "    Includes a source-specific emoji, title, summary, read more link, and channel ID.\n",
        "\n",
        "    Args:\n",
        "        title (str): The title of the news item.\n",
        "        link (str): The URL of the news item.\n",
        "        summary (str): A brief summary or description of the news item.\n",
        "        source_name_for_emoji_lookup (str): The clean source name used to retrieve the specific emoji.\n",
        "\n",
        "    Returns:\n",
        "        str: An HTML formatted string for the Telegram post.\n",
        "    \"\"\"\n",
        "    # Get the appropriate emoji based on the source name.\n",
        "    # Make sure get_source_emoji function is defined and accessible.\n",
        "    source_emoji = get_source_emoji(source_name_for_emoji_lookup)\n",
        "\n",
        "    emoji_link = \"üîó\"\n",
        "    emoji_channel = \"üì£\"\n",
        "\n",
        "    # Determine if a meaningful summary is available to include.\n",
        "    if not summary or summary.strip().lower() in [\n",
        "        \"no description available.\",\n",
        "        \"click to read more or join the discussion.\"\n",
        "    ]:\n",
        "        summary_text = \"\"  # If summary is generic or empty, don't include it.\n",
        "    else:\n",
        "        summary_text = f\"\\n\\n{summary}\"  # Add summary if available and meaningful.\n",
        "\n",
        "    post_content = (\n",
        "        f\"{source_emoji} <b>{title}</b>\"  # Source-specific emoji followed by bold title.\n",
        "        f\"{summary_text}\"  # Optional summary text.\n",
        "        f\"\\n\\n{emoji_link} <a href='{link}'>Read More</a>\"  # Hyperlinked \"Read More\".\n",
        "        f\"\\n\\n{emoji_channel} Channel: {TELEGRAM_CHANNEL_ID_FOR_FOOTER}\"  # Channel ID in footer.\n",
        "    )\n",
        "    return post_content\n",
        "\n",
        "# Example usage (you can test this in a separate cell if needed):\n",
        "# formatted_message = format_telegram_post(\n",
        "#     \"DeepMind Blog: New Breakthrough in AI Research\",\n",
        "#     \"https://example.com/ai-breakthrough\",\n",
        "#     \"Researchers have developed a novel algorithm that significantly improves the efficiency of neural networks for complex tasks.\",\n",
        "#     \"DeepMind Blog\" # Pass the exact source name string here for emoji lookup\n",
        "# )\n",
        "# print(formatted_message)\n",
        "\n",
        "# formatted_message_github = format_telegram_post(\n",
        "#     \"GitHub Trending (python): Awesome-Python-Project\",\n",
        "#     \"https://github.com/Awesome-Python-Project\",\n",
        "#     \"A curated list of awesome Python frameworks, libraries, software and resources.\",\n",
        "#     \"GitHub Trending (python)\" # Pass the exact source name string here\n",
        "# )\n",
        "# print(formatted_message_github)"
      ],
      "metadata": {
        "id": "vvOM7xmHmBTo"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from telegram.error import RetryAfter, TimedOut\n",
        "from telegram.constants import ParseMode\n",
        "\n",
        "async def send_news_to_telegram(news_items):\n",
        "    \"\"\"\n",
        "    Sends collected news items to the Telegram channel.\n",
        "    Manages Telegram's Flood Control by waiting when necessary.\n",
        "    Saves sent links to prevent duplicates.\n",
        "\n",
        "    Args:\n",
        "        news_items (list): A list of tuples, each containing\n",
        "                           (title, link, summary, source_name_for_emoji_lookup).\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Starting to send news to Telegram ---\")\n",
        "    if not news_items:\n",
        "        print(\"No new items to send.\")\n",
        "        return\n",
        "\n",
        "    sent_count = 0 # Removed filtered_count as keyword filtering is removed\n",
        "\n",
        "    for title, link, summary, source_name_for_emoji_lookup in news_items:\n",
        "        # Skip if the link has already been sent in a previous run.\n",
        "        if link in sent_links:\n",
        "            print(f\"SKIPPED (already sent): {title}\")\n",
        "            continue\n",
        "\n",
        "        # Format the message using the dedicated function.\n",
        "        # This function now expects 4 arguments including source_name_for_emoji_lookup\n",
        "        formatted_msg = format_telegram_post(title, link, summary, source_name_for_emoji_lookup)\n",
        "\n",
        "        try:\n",
        "            # Attempt to send the message.\n",
        "            await bot.send_message(chat_id=TELEGRAM_CHANNEL_ID, text=formatted_msg, parse_mode=ParseMode.HTML)\n",
        "            save_sent_link(link) # Save the link after successful sending.\n",
        "            print(f\"SUCCESS: '{title}' sent to Telegram.\")\n",
        "            sent_count += 1\n",
        "            await asyncio.sleep(3) # Wait to prevent hitting Telegram's rate limits.\n",
        "        except RetryAfter as e:\n",
        "            # Handle Telegram's flood control: wait the specified time and retry.\n",
        "            wait_time = e.retry_after + 1\n",
        "            print(f\"Telegram Flood Control: Waiting for {wait_time} seconds before retrying...\")\n",
        "            await asyncio.sleep(wait_time)\n",
        "\n",
        "            try:\n",
        "                # Retry sending the same message.\n",
        "                await bot.send_message(chat_id=TELEGRAM_CHANNEL_ID, text=formatted_msg, parse_mode=ParseMode.HTML)\n",
        "                save_sent_link(link)\n",
        "                print(f\"‚úÖSUCCESS (retry): '{title}' sent to Telegram after waiting.\")\n",
        "                sent_count += 1\n",
        "                await asyncio.sleep(3) # Wait again after successful retry.\n",
        "            except Exception as retry_e:\n",
        "                print(f\"‚ùåERROR (retry failed): Could not send '{title}' after waiting: {retry_e}\")\n",
        "        except TimedOut:\n",
        "            # Handle connection timeouts: wait briefly and continue to the next item.\n",
        "            print(f\"‚ùåTIMEOUT: Telegram API connection timed out for '{title}'. Retrying in 5 seconds.\")\n",
        "            await asyncio.sleep(5)\n",
        "        except Exception as e:\n",
        "            # Catch any other unexpected errors during sending.\n",
        "            print(f\"‚ùåERROR: Could not send '{title}' to Telegram: {e}\")\n",
        "\n",
        "    print(f\"--- Finished sending news to Telegram ---\")\n",
        "    print(f\"Total items sent: {sent_count}\")\n",
        ""
      ],
      "metadata": {
        "id": "IGxs6pNOmC0Z"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time # Ensure 'import time' is at the very top of your script or Colab notebook.\n",
        "\n",
        "async def main_bot_run():\n",
        "    \"\"\"\n",
        "    Orchestrates the entire news bot operation:\n",
        "    1. Loads previously sent links.\n",
        "    2. Collects news from all configured sources.\n",
        "    3. Sends new, filtered news items to Telegram.\n",
        "    4. Measures and prints the total execution time of the run.\n",
        "    \"\"\"\n",
        "    start_time = time.time() # Capture the start time for performance measurement.\n",
        "\n",
        "    global sent_links # Declare 'sent_links' as global to ensure proper access and modification.\n",
        "    sent_links = load_sent_links() # Load the set of links that have already been sent.\n",
        "\n",
        "    print(f\"\\n--- Bot run started at: {time.ctime()} ---\") # Log the start time of the bot's execution.\n",
        "\n",
        "    collected_news = collect_all_news() # Gather news items from all defined sources (RSS, GitHub, HN).\n",
        "    await send_news_to_telegram(collected_news) # Process and send the collected news to Telegram.\n",
        "\n",
        "    end_time = time.time() # Capture the end time after all operations are complete.\n",
        "    duration = end_time - start_time # Calculate the total duration of the run.\n",
        "\n",
        "    print(f\"--- Bot run finished at: {time.ctime()} ---\") # Log the finish time.\n",
        "    print(f\"Total execution time: {duration:.2f} seconds\") # Print the total time taken.\n",
        "\n",
        "# Execute the main asynchronous function.\n",
        "# This line should be placed at the very end of your script in a Colab environment.\n",
        "await main_bot_run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AE3d5CfAxIuv",
        "outputId": "aa54555a-b27a-44b9-949e-a48031f682da"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Bot run started at: Sun Jul 13 17:53:05 2025 ---\n",
            "\n",
            "--- Starting News Collection ---\n",
            "Retrieving news from RSS: Hugging Face Blog (https://huggingface.co/blog/rss.xml)\n",
            "Retrieving news from RSS: arXiv NLP (http://export.arxiv.org/rss/cs.CL)\n",
            "Retrieving news from RSS: OpenAI Blog (https://openai.com/blog/rss.xml)\n",
            "Retrieving news from RSS: Google AI Blog (https://ai.googleblog.com/feeds/posts/default)\n",
            "Retrieving news from RSS: Papers With Code (https://paperswithcode.com/rss)\n",
            "Retrieving news from RSS: DeepMind Blog (https://deepmind.com/blog/feed/basic/)\n",
            "Retrieving news from RSS: Kaggle Blog (https://www.kaggle.com/blog/rss/)\n",
            "Retrieving news from RSS: Microsoft AI Blog (https://blogs.microsoft.com/ai/feed/)\n",
            "Retrieving news from RSS: Meta AI Blog (https://ai.meta.com/blog/feed/)\n",
            "Retrieving news from RSS: Amazon Science Blog (https://www.amazon.science/rss.xml)\n",
            "Retrieving news from RSS: Towards Data Science (https://medium.com/feed/towards-data-science)\n",
            "Retrieving news from GitHub Trending: python (https://github.com/trending/python)\n",
            "Retrieving news from GitHub Trending: jupyter-notebook (https://github.com/trending/jupyter-notebook)\n",
            "Retrieving news from GitHub Trending: machine-learning (https://github.com/trending/machine-learning)\n",
            "Retrieving news from GitHub Trending: deep-learning (https://github.com/trending/deep-learning)\n",
            "Retrieving news from GitHub Trending: nlp (https://github.com/trending/nlp)\n",
            "Retrieving news from Hacker News\n",
            "Total unique new items collected: 70\n",
            "--- News Collection Finished ---\n",
            "\n",
            "--- Starting to send news to Telegram ---\n",
            "SUCCESS: 'OpenAI Blog: The EU Code of Practice and future of AI in Europe' sent to Telegram.\n",
            "SUCCESS: 'OpenAI Blog: Sam & Jony' sent to Telegram.\n",
            "SUCCESS: 'OpenAI Blog: Working with 400,000 teachers to shape the future of AI in schools' sent to Telegram.\n",
            "SUCCESS: 'OpenAI Blog: No-code personal agents, powered by GPT-4.1 and Realtime API' sent to Telegram.\n",
            "SUCCESS: 'OpenAI Blog: AI in Australia‚ÄîOpenAI‚Äôs Economic Blueprint' sent to Telegram.\n",
            "SUCCESS: 'OpenAI Blog: Customizable, no-code voice agent automation with GPT-4o' sent to Telegram.\n",
            "SUCCESS: 'OpenAI Blog: Driving scalable growth with OpenAI o3, GPT-4.1, and CUA' sent to Telegram.\n",
            "SUCCESS: 'OpenAI Blog: Toward understanding and preventing misalignment generalization' sent to Telegram.\n",
            "SUCCESS: 'OpenAI Blog: Preparing for future AI risks in biology' sent to Telegram.\n",
            "SUCCESS: 'OpenAI Blog: Introducing OpenAI for Government' sent to Telegram.\n",
            "SUCCESS: 'DeepMind Blog: AlphaGenome: AI for better understanding the genome' sent to Telegram.\n",
            "SUCCESS: 'DeepMind Blog: Gemini Robotics On-Device brings AI to local robotic devices' sent to Telegram.\n",
            "SUCCESS: 'DeepMind Blog: Gemini 2.5: Updates to our family of thinking models' sent to Telegram.\n",
            "SUCCESS: 'DeepMind Blog: We‚Äôre expanding our Gemini 2.5 family of models' sent to Telegram.\n",
            "SUCCESS: 'DeepMind Blog: Behind ‚ÄúANCESTRA‚Äù: combining Veo with live-action filmmaking' sent to Telegram.\n",
            "SUCCESS: 'DeepMind Blog: How we're supporting better tropical cyclone prediction with AI' sent to Telegram.\n",
            "SUCCESS: 'DeepMind Blog: Advanced audio dialog and generation with Gemini 2.5' sent to Telegram.\n",
            "SUCCESS: 'DeepMind Blog: Fuel your creativity with new generative media models and tools' sent to Telegram.\n",
            "SUCCESS: 'DeepMind Blog: Announcing Gemma 3n preview: Powerful, efficient, mobile-first AI' sent to Telegram.\n",
            "SUCCESS: 'DeepMind Blog: Advancing Gemini's security safeguards' sent to Telegram.\n",
            "SUCCESS: 'Microsoft AI Blog: A conversation with Kevin Scott: What‚Äôs next in AI' sent to Telegram.\n",
            "SUCCESS: 'Microsoft AI Blog: From Hot Wheels to handling content: How brands are using Microsoft AI to be more productive and imaginative' sent to Telegram.\n",
            "SUCCESS: 'Microsoft AI Blog: Microsoft open sources its ‚Äòfarm of the future‚Äô toolkit' sent to Telegram.\n",
            "SUCCESS: 'Microsoft AI Blog: How data and AI will transform contact centres for financial services' sent to Telegram.\n",
            "SUCCESS: 'Microsoft AI Blog: AI-equipped drones study dolphins on the edge of extinction' sent to Telegram.\n",
            "SUCCESS: 'Microsoft AI Blog: Online math tutoring service uses AI to help boost students‚Äô skills and confidence' sent to Telegram.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CancelledError",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-93-1475828216.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Execute the main asynchronous function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# This line should be placed at the very end of your script in a Colab environment.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mawait\u001b[0m \u001b[0mmain_bot_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-93-1475828216.py\u001b[0m in \u001b[0;36mmain_bot_run\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mcollected_news\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollect_all_news\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Gather news items from all defined sources (RSS, GitHub, HN).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mawait\u001b[0m \u001b[0msend_news_to_telegram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollected_news\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Process and send the collected news to Telegram.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Capture the end time after all operations are complete.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-92-3148979710.py\u001b[0m in \u001b[0;36msend_news_to_telegram\u001b[0;34m(news_items)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"SUCCESS: '{title}' sent to Telegram.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0msent_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Wait to prevent hitting Telegram's rate limits.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRetryAfter\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;31m# Handle Telegram's flood control: wait the specified time and retry.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/asyncio/tasks.py\u001b[0m in \u001b[0;36msleep\u001b[0;34m(delay, result)\u001b[0m\n\u001b[1;32m    647\u001b[0m                         future, result)\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCancelledError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C2PFJENoxJBh"
      },
      "execution_count": 60,
      "outputs": []
    }
  ]
}
